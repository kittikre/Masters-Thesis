{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri May  6 13:51:53 2022\n",
    "\n",
    "@author: Kitti\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import elu\n",
    "\n",
    "from braindecode.util import np_to_th\n",
    "from braindecode.models.modules import Expression, Ensure4d, AvgPool2dWithConv\n",
    "from braindecode.models.functions import (\n",
    "    safe_log, square, transpose_time_to_spat,identity, squeeze_final_output\n",
    ")\n",
    "from TransformFunction import reshape_lstm_input, extract_output_from_lstm #, permute_final_output\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf8cc0",
   "metadata": {
    "title": "Class of the ShallowCNNLSTM model"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ShallowCNNLSTM(nn.Sequential):\n",
    "    \"\"\"Shallow ConvNet model from Schirrmeister et al 2017.\n",
    "\n",
    "    Model described in [Schirrmeister2017]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_chans : int\n",
    "        XXX\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [Schirrmeister2017] Schirrmeister, R. T., Springenberg, J. T., Fiederer,\n",
    "       L. D. J., Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F.\n",
    "       & Ball, T. (2017).\n",
    "       Deep learning with convolutional neural networks for EEG decoding and\n",
    "       visualization.\n",
    "       Human Brain Mapping , Aug. 2017.\n",
    "       Online: http://dx.doi.org/10.1002/hbm.23730\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans,\n",
    "        n_classes,\n",
    "        input_window_samples=None,\n",
    "        n_filters_time=40,\n",
    "        filter_time_length=25,\n",
    "        n_filters_spat=40,\n",
    "        pool_time_length=75,\n",
    "        pool_time_stride=15,\n",
    "        final_conv_length=30,\n",
    "        conv_nonlin=square,\n",
    "        pool_mode=\"mean\",\n",
    "        pool_nonlin=safe_log,\n",
    "        split_first_layer=True,\n",
    "        batch_norm=True,\n",
    "        batch_norm_alpha=0.1,\n",
    "        drop_prob=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if final_conv_length == \"auto\":\n",
    "            assert input_window_samples is not None\n",
    "        self.in_chans = in_chans\n",
    "        self.n_classes = n_classes\n",
    "        self.input_window_samples = input_window_samples\n",
    "        self.n_filters_time = n_filters_time\n",
    "        self.filter_time_length = filter_time_length\n",
    "        self.n_filters_spat = n_filters_spat\n",
    "        self.pool_time_length = pool_time_length\n",
    "        self.pool_time_stride = pool_time_stride\n",
    "        self.final_conv_length = final_conv_length\n",
    "        self.conv_nonlin = conv_nonlin\n",
    "        self.pool_mode = pool_mode\n",
    "        self.pool_nonlin = pool_nonlin\n",
    "        self.split_first_layer = split_first_layer\n",
    "        self.batch_norm = batch_norm\n",
    "        self.batch_norm_alpha = batch_norm_alpha\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.add_module(\"ensuredims\", Ensure4d())\n",
    "        pool_class = dict(max=nn.MaxPool2d, mean=nn.AvgPool2d)[self.pool_mode]\n",
    "        if self.split_first_layer:\n",
    "            self.add_module(\"dimshuffle\", Expression(transpose_time_to_spat))\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    1,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=1,\n",
    "                ),\n",
    "            )\n",
    "            self.add_module(\n",
    "                \"conv_spat\",\n",
    "                nn.Conv2d(\n",
    "                    self.n_filters_time,\n",
    "                    self.n_filters_spat,\n",
    "                    (1, self.in_chans),\n",
    "                    stride=1,\n",
    "                    bias=not self.batch_norm,\n",
    "                    #padding=\"same\",\n",
    "                \n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_spat\n",
    "        else:\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    self.in_chans,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=1,\n",
    "                    bias=not self.batch_norm,\n",
    "                    #padding=\"same\",\n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_time\n",
    "        if self.batch_norm:\n",
    "            self.add_module(\n",
    "                \"bnorm\",\n",
    "                nn.BatchNorm2d(\n",
    "                    n_filters_conv, momentum=self.batch_norm_alpha, affine=True\n",
    "                ),\n",
    "            )\n",
    "        self.add_module(\"conv_nonlin_exp\", Expression(self.conv_nonlin))\n",
    "        self.add_module(\n",
    "            \"pool\",\n",
    "            pool_class(\n",
    "                kernel_size=(self.pool_time_length, 1),\n",
    "                stride=(self.pool_time_stride, 1),\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"pool_nonlin_exp\", Expression(self.pool_nonlin))\n",
    "        self.add_module(\"drop\", nn.Dropout(p=self.drop_prob))\n",
    "        self.eval()\n",
    "        if self.final_conv_length == \"auto\":\n",
    "            out = self(\n",
    "                np_to_th(\n",
    "                    np.ones(\n",
    "                        (1, self.in_chans, self.input_window_samples, 1),\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            n_out_time = out.cpu().data.numpy().shape[2]\n",
    "            self.final_conv_length = n_out_time\n",
    "        self.add_module(\n",
    "            \"conv_classifier\",\n",
    "            nn.Conv2d(\n",
    "                n_filters_conv,\n",
    "                self.n_classes,\n",
    "                (self.final_conv_length, 1),\n",
    "                bias=True,\n",
    "                #padding=\"same\",\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"reshapeinput\", Expression(reshape_lstm_input))\n",
    "\n",
    "        self.add_module(\n",
    "            \"LSTM\", \n",
    "            nn.LSTM(740, 370, 1,\n",
    "                batch_first=True\n",
    "            ),\n",
    "        ) \n",
    "        \n",
    "        self.add_module(\"extract_lstm\", Expression(extract_output_from_lstm))\n",
    "        \n",
    "        self.add_module(\n",
    "            \"Linear\",\n",
    "             nn.Linear(\n",
    "                 in_features= 370,\n",
    "                 out_features = 1,\n",
    "             ),\n",
    "        )\n",
    "        self.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "        \n",
    "        #self.add_module(\"permute\", Expression(permute_final_output))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.add_module(\"squeeze\", Expression(squeeze_final_output))\n",
    "        \n",
    "\n",
    "        \n",
    "        # Initialization, xavier is same as in paper...\n",
    "        init.xavier_uniform_(self.conv_time.weight, gain=1)\n",
    "        # maybe no bias in case of no split layer and batch norm\n",
    "        if self.split_first_layer or (not self.batch_norm):\n",
    "            init.constant_(self.conv_time.bias, 0)\n",
    "        if self.split_first_layer:\n",
    "            init.xavier_uniform_(self.conv_spat.weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                init.constant_(self.conv_spat.bias, 0)\n",
    "        if self.batch_norm:\n",
    "            init.constant_(self.bnorm.weight, 1)\n",
    "            init.constant_(self.bnorm.bias, 0)\n",
    "        init.xavier_uniform_(self.conv_classifier.weight, gain=1)\n",
    "        init.constant_(self.conv_classifier.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f9ebc",
   "metadata": {
    "title": "#%% Class of the DeepCNNLSTM model"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DeepCNNLSTM(nn.Sequential):\n",
    "    \"\"\"Deep ConvNet model from Schirrmeister et al 2017.,\n",
    "    completed with an LSTM layer and Sigmoid activation (instead of softmax).\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_chans : int\n",
    "        XXX\n",
    "    References\n",
    "    ----------\n",
    "    .. [Schirrmeister2017] Schirrmeister, R. T., Springenberg, J. T., Fiederer,\n",
    "       L. D. J., Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F.\n",
    "       & Ball, T. (2017).\n",
    "       Deep learning with convolutional neural networks for EEG decoding and\n",
    "       visualization.\n",
    "       Human Brain Mapping , Aug. 2017.\n",
    "       Online: http://dx.doi.org/10.1002/hbm.23730\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans,\n",
    "        n_classes,\n",
    "        input_window_samples,\n",
    "        final_conv_length,\n",
    "        n_filters_time=25,\n",
    "        n_filters_spat=25,\n",
    "        filter_time_length=10,\n",
    "        pool_time_length=3,\n",
    "        pool_time_stride=3,\n",
    "        n_filters_2=50,\n",
    "        filter_length_2=10,\n",
    "        n_filters_3=100,\n",
    "        filter_length_3=10,\n",
    "        n_filters_4=200,\n",
    "        filter_length_4=10,\n",
    "        first_nonlin=elu,\n",
    "        first_pool_mode=\"max\",\n",
    "        first_pool_nonlin=identity,\n",
    "        later_nonlin=elu,\n",
    "        later_pool_mode=\"max\",\n",
    "        later_pool_nonlin=identity,\n",
    "        drop_prob=0.5,\n",
    "        double_time_convs=False,\n",
    "        split_first_layer=True,\n",
    "        batch_norm=True,\n",
    "        batch_norm_alpha=0.1,\n",
    "        stride_before_pool=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if final_conv_length == \"auto\":\n",
    "            assert input_window_samples is not None\n",
    "        self.in_chans = in_chans\n",
    "        self.n_classes = n_classes\n",
    "        self.input_window_samples = input_window_samples\n",
    "        self.final_conv_length = final_conv_length\n",
    "        self.n_filters_time = n_filters_time\n",
    "        self.n_filters_spat = n_filters_spat\n",
    "        self.filter_time_length = filter_time_length\n",
    "        self.pool_time_length = pool_time_length\n",
    "        self.pool_time_stride = pool_time_stride\n",
    "        self.n_filters_2 = n_filters_2\n",
    "        self.filter_length_2 = filter_length_2\n",
    "        self.n_filters_3 = n_filters_3\n",
    "        self.filter_length_3 = filter_length_3\n",
    "        self.n_filters_4 = n_filters_4\n",
    "        self.filter_length_4 = filter_length_4\n",
    "        self.first_nonlin = first_nonlin\n",
    "        self.first_pool_mode = first_pool_mode\n",
    "        self.first_pool_nonlin = first_pool_nonlin\n",
    "        self.later_nonlin = later_nonlin\n",
    "        self.later_pool_mode = later_pool_mode\n",
    "        self.later_pool_nonlin = later_pool_nonlin\n",
    "        self.drop_prob = drop_prob\n",
    "        self.double_time_convs = double_time_convs\n",
    "        self.split_first_layer = split_first_layer\n",
    "        self.batch_norm = batch_norm\n",
    "        self.batch_norm_alpha = batch_norm_alpha\n",
    "        self.stride_before_pool = stride_before_pool\n",
    "\n",
    "        if self.stride_before_pool:\n",
    "            conv_stride = self.pool_time_stride\n",
    "            pool_stride = 1\n",
    "        else:\n",
    "            conv_stride = 1\n",
    "            pool_stride = self.pool_time_stride\n",
    "        self.add_module(\"ensuredims\", Ensure4d())\n",
    "        pool_class_dict = dict(max=nn.MaxPool2d, mean=AvgPool2dWithConv)\n",
    "        first_pool_class = pool_class_dict[self.first_pool_mode]\n",
    "        later_pool_class = pool_class_dict[self.later_pool_mode]\n",
    "        if self.split_first_layer:\n",
    "            self.add_module(\"dimshuffle\", Expression(transpose_time_to_spat))\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    1,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=1,\n",
    "                ),\n",
    "            )\n",
    "            self.add_module(\n",
    "                \"conv_spat\",\n",
    "                nn.Conv2d(\n",
    "                    self.n_filters_time,\n",
    "                    self.n_filters_spat,\n",
    "                    (1, self.in_chans),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_spat\n",
    "        else:\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    self.in_chans,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_time\n",
    "        if self.batch_norm:\n",
    "            self.add_module(\n",
    "                \"bnorm\",\n",
    "                nn.BatchNorm2d(\n",
    "                    n_filters_conv,\n",
    "                    momentum=self.batch_norm_alpha,\n",
    "                    affine=True,\n",
    "                    eps=1e-5,\n",
    "                ),\n",
    "            )\n",
    "        self.add_module(\"conv_nonlin\", Expression(self.first_nonlin))\n",
    "        self.add_module(\n",
    "            \"pool\",\n",
    "            first_pool_class(\n",
    "                kernel_size=(self.pool_time_length, 1), stride=(pool_stride, 1)\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"pool_nonlin\", Expression(self.first_pool_nonlin))\n",
    "\n",
    "        def add_conv_pool_block(\n",
    "            model, n_filters_before, n_filters, filter_length, block_nr\n",
    "        ):\n",
    "            suffix = \"_{:d}\".format(block_nr)\n",
    "            self.add_module(\"drop\" + suffix, nn.Dropout(p=self.drop_prob))\n",
    "            self.add_module(\n",
    "                \"conv\" + suffix,\n",
    "                nn.Conv2d(\n",
    "                    n_filters_before,\n",
    "                    n_filters,\n",
    "                    (filter_length, 1),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            if self.batch_norm:\n",
    "                self.add_module(\n",
    "                    \"bnorm\" + suffix,\n",
    "                    nn.BatchNorm2d(\n",
    "                        n_filters,\n",
    "                        momentum=self.batch_norm_alpha,\n",
    "                        affine=True,\n",
    "                        eps=1e-5,\n",
    "                    ),\n",
    "                )\n",
    "            self.add_module(\"nonlin\" + suffix, Expression(self.later_nonlin))\n",
    "\n",
    "            self.add_module(\n",
    "                \"pool\" + suffix,\n",
    "                later_pool_class(\n",
    "                    kernel_size=(self.pool_time_length, 1),\n",
    "                    stride=(pool_stride, 1),\n",
    "                ),\n",
    "            )\n",
    "            self.add_module(\n",
    "                \"pool_nonlin\" + suffix, Expression(self.later_pool_nonlin)\n",
    "            )\n",
    "\n",
    "        add_conv_pool_block(\n",
    "            self, n_filters_conv, self.n_filters_2, self.filter_length_2, 2\n",
    "        )\n",
    "        add_conv_pool_block(\n",
    "            self, self.n_filters_2, self.n_filters_3, self.filter_length_3, 3\n",
    "        )\n",
    "        add_conv_pool_block(\n",
    "            self, self.n_filters_3, self.n_filters_4, self.filter_length_4, 4\n",
    "        )\n",
    "\n",
    "        # self.add_module('drop_classifier', nn.Dropout(p=self.drop_prob))\n",
    "        self.eval()\n",
    "        if self.final_conv_length == \"auto\":\n",
    "            out = self(\n",
    "                np_to_th(\n",
    "                    np.ones(\n",
    "                        (1, self.in_chans, self.input_window_samples, 1),\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            n_out_time = out.cpu().data.numpy().shape[2]\n",
    "            self.final_conv_length = n_out_time\n",
    "        self.add_module(\n",
    "            \"conv_classifier\",\n",
    "            nn.Conv2d(\n",
    "                self.n_filters_4,\n",
    "                self.n_classes,\n",
    "                (self.final_conv_length, 1),\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.add_module(\"reshapeinput\", Expression(reshape_lstm_input))\n",
    "        \n",
    "        self.add_module(\n",
    "            \"LSTM\", \n",
    "            nn.LSTM(138, 69, 1,\n",
    "                batch_first=True\n",
    "            ),\n",
    "        ) \n",
    "        \n",
    "        self.add_module(\"extract_lstm\", Expression(extract_output_from_lstm))\n",
    "        \n",
    "        self.add_module(\n",
    "            \"Linear\",\n",
    "             nn.Linear(\n",
    "                 in_features= 69,\n",
    "                 out_features = 1,\n",
    "             ),\n",
    "        )\n",
    "        self.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "        \n",
    "        '''\n",
    "        self.add_module(\"softmax\", nn.LogSoftmax(dim=1))\n",
    "        self.add_module(\"squeeze\", Expression(squeeze_final_output))\n",
    "        '''\n",
    "        # Initialization, xavier is same as in our paper...\n",
    "        # was default from lasagne\n",
    "        init.xavier_uniform_(self.conv_time.weight, gain=1)\n",
    "        # maybe no bias in case of no split layer and batch norm\n",
    "        if self.split_first_layer or (not self.batch_norm):\n",
    "            init.constant_(self.conv_time.bias, 0)\n",
    "        if self.split_first_layer:\n",
    "            init.xavier_uniform_(self.conv_spat.weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                init.constant_(self.conv_spat.bias, 0)\n",
    "        if self.batch_norm:\n",
    "            init.constant_(self.bnorm.weight, 1)\n",
    "            init.constant_(self.bnorm.bias, 0)\n",
    "        param_dict = dict(list(self.named_parameters()))\n",
    "        for block_nr in range(2, 5):\n",
    "            conv_weight = param_dict[\"conv_{:d}.weight\".format(block_nr)]\n",
    "            init.xavier_uniform_(conv_weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                conv_bias = param_dict[\"conv_{:d}.bias\".format(block_nr)]\n",
    "                init.constant_(conv_bias, 0)\n",
    "            else:\n",
    "                bnorm_weight = param_dict[\"bnorm_{:d}.weight\".format(block_nr)]\n",
    "                bnorm_bias = param_dict[\"bnorm_{:d}.bias\".format(block_nr)]\n",
    "                init.constant_(bnorm_weight, 1)\n",
    "                init.constant_(bnorm_bias, 0)\n",
    "\n",
    "        init.xavier_uniform_(self.conv_classifier.weight, gain=1)\n",
    "        init.constant_(self.conv_classifier.bias, 0)\n",
    "\n",
    "        # Start in eval mode\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0622afc",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Function for creating instances of the three models"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model(model_name, in_chans, n_classes, input_window_samples, final_conv_length):\n",
    "    \n",
    "    \n",
    "    if model_name == \"shallow\":\n",
    "        shallowcnn = ShallowFBCSPNet(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )   \n",
    "        return shallowcnn\n",
    "        \n",
    "    elif model_name == \"deep\":\n",
    "        deepcnn = Deep4Net(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )\n",
    "        return deepcnn\n",
    "        \n",
    "    elif model_name == \"hybrid\":\n",
    "        hybrid = DeepCNNLSTM(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )\n",
    "        return hybrid\n",
    "            \n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
