{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee213360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e26c48",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import import_ipynb\n",
    "import numpy as np\n",
    "from PreProcessing_v1 import import_tuh_abnormal\n",
    "from DataTransform import data_transform, train_valid_test_split, get_parameters_for_model\n",
    "import torch\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, scale as multiply\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "from torch import optim\n",
    "from Models import ShallowCNNLSTM\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# # Importing TUH Abnormal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5881041",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "TUH_PATH = 'C:/Users/Kitti/Documents/Thesis/TUH/Abnormal/SSample'\n",
    "#TUH_PATH = 'TUH EEG Abnormal dataset/Abnormal/' # specify the path to the TUH Abnormal dataset\n",
    "N_JOBS = 2  # specify the number of jobs for loading and windowing\n",
    "\n",
    "# parameters to be defined for the preprocessing pipeline\n",
    "TMIN = 1 * 60\n",
    "TMAX = 5 * 60 \n",
    "SFREQ = 100\n",
    "CLIPPING = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048f217",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tuh_abnormal = import_tuh_abnormal(TUH_PATH, N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52356409",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_ch_mapping():\n",
    "    short_ch_names = sorted([\n",
    "        'A1', 'A2',\n",
    "        'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\n",
    "    ar_ch_names = sorted([\n",
    "        'EEG A1-REF', 'EEG A2-REF',\n",
    "        'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "        'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "        'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "        'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "    le_ch_names = sorted([\n",
    "        'EEG A1-LE', 'EEG A2-LE',\n",
    "        'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "        'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "        'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "        'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "    assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "    ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        ar_ch_names, short_ch_names)}\n",
    "    le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        le_ch_names, short_ch_names)}\n",
    "    ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}    \n",
    "    return short_ch_names, ch_mapping\n",
    "\n",
    "\n",
    "def select_by_channels(ds, short_ch_names, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "    \n",
    "    \n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])\n",
    "    \n",
    "short_ch_names, ch_mapping = create_ch_mapping()\n",
    "\n",
    "preprocessors = [\n",
    "        Preprocessor(custom_crop, tmin=TMIN, tmax=TMAX, include_tmax=True,\n",
    "                     apply_on_array=False),\n",
    "        Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'), # mne Raw class function\n",
    "        Preprocessor(custom_rename_channels, mapping=ch_mapping, # rename channels to short channel names\n",
    "                     apply_on_array=False), #\n",
    "        Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True), # mne Raw class function\n",
    "        Preprocessor(multiply, factor=1e6, apply_on_array=True), # scaling signals to microvolt\n",
    "        Preprocessor(np.clip, a_min=-CLIPPING, a_max=CLIPPING, apply_on_array=True), # clip outlier values to +/- 800 micro volts\n",
    "        Preprocessor('resample', sfreq=SFREQ), # mne Raw class function\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tuh_preproc = preprocess(\n",
    "        concat_ds=tuh_abnormal,\n",
    "        preprocessors=preprocessors,\n",
    "        n_jobs=N_JOBS,\n",
    "        save_dir=None\n",
    "    )\n",
    "\n",
    "\n",
    "# # Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddb4c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from braindecode.datasets.tuh import TUHAbnormal, TUH\n",
    "# from braindecode.models import get_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tuh_train, tuh_val, tuh_test = train_valid_test_split(tuh_preproc, train_size=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a9efc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract number of chans and time steps from dataset\n",
    "in_chans, input_size_samples = get_parameters_for_model(tuh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TRAIN_SIZE=0.9\n",
    "INPUT_WIN_SAMPLES = 6000\n",
    "BATCH_SIZE=64\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "# Set random seed to be able to roughly reproduce results\n",
    "# Note that with cudnn benchmark set to True, GPU indeterminism\n",
    "# may still make results substantially different between runs.\n",
    "# To obtain more consistent results at the cost of increased computation time,\n",
    "# you can set `cudnn_benchmark=False` in `set_random_seeds`\n",
    "# or remove `torch.backends.cudnn.benchmark = True`\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "modelh = ShallowCNNLSTM(\n",
    "    in_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=INPUT_WIN_SAMPLES,\n",
    "    final_conv_length=25,\n",
    ")\n",
    "\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    modelh.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShallowFBCSPNet(\n",
    "    in_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=INPUT_WIN_SAMPLES,\n",
    "    final_conv_length=25,\n",
    ")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c4310",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = data_transform(tuh_train, tuh_val, tuh_test, model, train_size=TRAIN_SIZE, batch_size=BATCH_SIZE, input_window_samples=INPUT_WIN_SAMPLES, in_chans = in_chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(train_loader)\n",
    "\n",
    "\n",
    "# # Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e4b87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from TrainingValidationTesting import train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33576132",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# hyperparameters for training the model\n",
    "lr =  0.01\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "n_epochs = 1  \n",
    "patience = 10\n",
    "\n",
    "# Using multiple GPUs\n",
    "# model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8a6ed",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "trained_model, train_losses, train_accs, valid_losses = train_model(model, device, criterion, optimizer, train_loader, val_loader, n_epochs, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcf047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trained_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68aa56",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_test, y_test, y_pred, accuracy = test_model(device, trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the trained model\n",
    "\n",
    "PATH = './cnnshallow.pth'\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "\n",
    "#how to reload the saved model:\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=INPUT_WIN_SAMPLES,\n",
    "    final_conv_length=1,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, y_pred, accuracy = test_model(device, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6dc3f",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Evaluation of the results"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd3757",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Transform tensors from test_model"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.flatten().cpu()\n",
    "y_test = y_test.flatten().cpu()\n",
    "y_pred = y_pred.flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa1bfa",
   "metadata": {
    "title": "Training losses and accuracy plot"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(train_losses, marker=\"o\", color=\"orangered\", label=\"Training loss\")\n",
    "ax.set_xlabel(\"Number of epochs\")\n",
    "ax.set_ylabel(\"Loss\", color=\"orangered\")\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(train_accs, marker=\"o\", color=\"cornflowerblue\", label=\"Training accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\", color=\"cornflowerblue\")\n",
    "\n",
    "plt.title(\"Training loss and accuracy per epoch\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a file\n",
    "'''\n",
    "fig.savefig('two_different_y_axis_for_single_python_plot_with_twinx.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# In[87]: Losses plot\n",
    "\n",
    "plt.plot(train_losses, marker=\".\", color=\"cornflowerblue\", label='Training loss')\n",
    "plt.plot(valid_losses, marker=\".\", color=\"mediumseagreen\", label='Validation loss')\n",
    "plt.title('Training and Validation Losses', fontsize=14)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0813c4",
   "metadata": {
    "title": "ROC Curve plot"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "The ROC Curve plots two parameters: the True Positive Rate (TPR), a synonim to recall,\n",
    "and the False Positive Rate (FPR). \n",
    "The plot also shows the ROC AUC score.\n",
    "By default, the class considered as the positive (It means Abnormal in our case).\n",
    "\n",
    "'''\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred, pos_label=None)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[90]: Confusion matrix and Classification Report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cl_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c5c3f",
   "metadata": {
    "title": "Print classification report"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4ed7b",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Plot Confusion matrix"
   },
   "outputs": [],
   "source": [
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='YlGn')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
