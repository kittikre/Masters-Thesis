{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon May  2 13:13:08 2022\n",
    "\n",
    "Data functions for handling the TUH Abnormal dataset\n",
    "\n",
    "Each method has its own description in it's header section.'\n",
    "The methods defined in this file are:\n",
    "    \n",
    "    \n",
    "The classes defined in this file are:\n",
    "    \n",
    "\n",
    "@author: Kitti\n",
    "\"\"\"\n",
    "\n",
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "from braindecode.datasets.tuh import TUHAbnormal, TUH\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows, scale as multiply)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee0d86",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Function for importing the dataset"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_tuh_abnormal(path, n_jobs=2, target_name='pathological', preload=False, add_physician_reports=True):\n",
    "    tuh_abnormal = TUHAbnormal(\n",
    "        path=path,\n",
    "        recording_ids=None,\n",
    "        target_name=target_name,\n",
    "        preload=preload,\n",
    "        add_physician_reports=add_physician_reports,\n",
    "        n_jobs=1 if TUH.__name__ == '_TUHMock' else n_jobs,  # Mock dataset can't be loaded in parallel\n",
    "    )\n",
    "    \n",
    "    return tuh_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a997951",
   "metadata": {
    "title": "Preprocessing functions"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_ch_mapping():\n",
    "    short_ch_names = sorted([\n",
    "        'A1', 'A2',\n",
    "        'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\n",
    "    ar_ch_names = sorted([\n",
    "        'EEG A1-REF', 'EEG A2-REF',\n",
    "        'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "        'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "        'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "        'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "    le_ch_names = sorted([\n",
    "        'EEG A1-LE', 'EEG A2-LE',\n",
    "        'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "        'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "        'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "        'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "    assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "    ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        ar_ch_names, short_ch_names)}\n",
    "    le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        le_ch_names, short_ch_names)}\n",
    "    ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}    \n",
    "    return short_ch_names, ch_mapping\n",
    "\n",
    "\n",
    "def select_by_channels(ds, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=(tmax+tmin), include_tmax=include_tmax)\n",
    "    \n",
    "    \n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f79fb4",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Preprocessing pipeline function"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_dataset(tuh_abnormal, tmin, tmax, sfreq, clipping,  ch_mapping, short_ch_names, include_tmax=True, n_jobs=2):\n",
    "\n",
    "    preprocessors = [\n",
    "        Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=include_tmax,\n",
    "                     apply_on_array=False),\n",
    "        Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'), # mne Raw class function\n",
    "        Preprocessor(custom_rename_channels, mapping=ch_mapping, # rename channels to short channel names\n",
    "                     apply_on_array=False), #\n",
    "        Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True), # mne Raw class function\n",
    "        Preprocessor(multiply, factor=1e6, apply_on_array=True), # scaling signals to microvolt\n",
    "        Preprocessor(np.clip, a_min=-clipping, a_max=clipping, apply_on_array=True), # clip outlier values to +/- 800 micro volts\n",
    "        Preprocessor('resample', sfreq=sfreq), # mne Raw class function\n",
    "    ]\n",
    "    \n",
    "    tuh_preproc = preprocess(\n",
    "        concat_ds=tuh_abnormal,\n",
    "        preprocessors=preprocessors,\n",
    "        n_jobs=N_JOBS,\n",
    "        save_dir=None\n",
    "    )\n",
    "    \n",
    "    return tuh_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5f1ba",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Single function to call for importing and preprocessing dataset"
   },
   "outputs": [],
   "source": [
    "\n",
    "def import_and_preprocess(path, n_jobs, tmin, tmax, sfreq, clipping, include_tmax=True):\n",
    "    \n",
    "    tuh_abnormal_raw = import_tuh_abnormal(path, n_jobs)\n",
    "    short_ch_names, ch_mapping = create_ch_mapping()\n",
    "    tuh_abnormal_selected = select_by_channels(tuh_abnormal_raw, ch_mapping)\n",
    "    tuh_abnormal_preproc = preprocess_dataset(tuh_abnormal_selected, tmin, tmax, sfreq, clipping,  ch_mapping, short_ch_names, include_tmax, n_jobs)\n",
    "    \n",
    "    return tuh_abnormal_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee66d5",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Testing functions"
   },
   "outputs": [],
   "source": [
    "\n",
    "# required parameters\n",
    "TUH_PATH = 'C:/Users/Kitti/Documents/Thesis/TUH/Abnormal/SSample/' # specify the path to the TUH Abnormal dataset\n",
    "N_JOBS = 2  # specify the number of jobs for loading and windowing\n",
    "\n",
    "# parameters to be defined for the preprocessing pipeline\n",
    "TMIN = 1 * 60\n",
    "TMAX = 16 * 60 # as the first minute of each recording is cropped, n+1 minutes must be added\n",
    "SFREQ = 100\n",
    "CLIPPING = 800\n",
    "\n",
    "tuh_preproc = import_and_preprocess(TUH_PATH, N_JOBS, TMIN, TMAX, SFREQ, CLIPPING)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
