{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a79213d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498779df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01eaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import packages\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446aace",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "\n",
    "def train_model(model, device, criterion, optimizer, train_loader, valid_loader, n_epochs=5, early_stop_patience=2):\n",
    "    \n",
    "    for i in range(1, 1000000):\n",
    "        if len(train_loader) / i <= 20:\n",
    "            print_every = i\n",
    "            break\n",
    "    \n",
    "    model.train()\n",
    "    the_last_loss = 100\n",
    "    trigger_times = 0\n",
    "    train_losses_per_epoch, valid_losses_per_epoch = [], []\n",
    "    train_accs_per_epoch, valid_accs_per_epoch = [], []\n",
    "        \n",
    "    \n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, inds = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            #labels = torch.clone(labels.long())\n",
    "            \n",
    "            # sending input to GPU/CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #labels = torch.squeeze(labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = torch.squeeze(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            labels = labels.squeeze()\n",
    "            total += labels.numel()\n",
    "            \n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            # correct += predicted.eq(labels).numel()\n",
    "          \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            train_acc = correct/total\n",
    "            running_acc += train_acc\n",
    "            \n",
    "            \n",
    "            if i % print_every == print_every-1 or i+1 == len(train_loader):\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "                print('Time: {}. . [{}/{}, {}/{}] train_loss: {:.6}, train_acc: {:.3}'.format(current_time, epoch+1, n_epochs, i+1, len(train_loader), running_loss/(i+1), running_acc/(i+1)))\n",
    "    \n",
    "        train_losses_per_epoch.append(running_loss/len(train_loader))\n",
    "        train_accs_per_epoch.append(running_acc/len(train_loader))\n",
    "        current_loss, current_acc = validate_model(model, device, valid_loader, criterion)\n",
    "        model.train()\n",
    "        print('Current Validation Loss: {:.6}, Accuracy: {:.3}'.format(current_loss, current_acc))\n",
    "        \n",
    "            \n",
    "        if current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('Trigger Times:', trigger_times)\n",
    "    \n",
    "            if trigger_times >= early_stop_patience:\n",
    "                print('Early Stopping!\\nStart the test process.')\n",
    "                return model, train_losses_per_epoch, valid_losses_per_epoch\n",
    "                # this needs to be modified to start the testing process -> return model if turn into a function\n",
    "    \n",
    "        else:\n",
    "            print('Trigger Times: 0')\n",
    "            trigger_times = 0\n",
    "    \n",
    "        the_last_loss = current_loss\n",
    "        valid_losses_per_epoch.append(current_loss)\n",
    "        valid_accs_per_epoch.append(current_acc)\n",
    "    \n",
    "    print('Finished Training')        \n",
    "    return model, train_losses_per_epoch, train_accs_per_epoch, valid_losses_per_epoch, valid_accs_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdeafe3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_model(model, device, valid_loader, loss_function):\n",
    "\n",
    "     model.eval()\n",
    "     loss_total = 0\n",
    "     correct = 0\n",
    "     total = 0\n",
    "\n",
    "     # Test validation data\n",
    "     with torch.no_grad():\n",
    "         for data in valid_loader:\n",
    "             inputs, labels, inds = data\n",
    "             inputs = inputs.float()\n",
    "             labels = labels.float()\n",
    "             #labels = torch.clone(labels.long())\n",
    "             \n",
    "             #Sending input to GPU/CPU\n",
    "             inputs, labels = inputs.to(device),  labels.to(device)\n",
    "             \n",
    "\n",
    "             outputs = model(inputs)\n",
    "             outputs = torch.squeeze(outputs, 1)\n",
    "             loss = loss_function(outputs, labels)\n",
    "             loss_total += loss.item()\n",
    "             \n",
    "             # Prediction for generating validation accuracy\n",
    "             _, predicted = torch.max(outputs.data, 1)\n",
    "             labels = labels.squeeze()\n",
    "             total += labels.numel()\n",
    "             correct += predicted.eq(labels).sum().item()\n",
    "     \n",
    "     accuracy = correct/total\n",
    "     return loss_total / len(valid_loader), accuracy\n",
    "\n",
    "    \n",
    "# Test function\n",
    "\n",
    "def test_model(device, model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    inputs_all = torch.tensor([])\n",
    "    labels_all = torch.tensor([])\n",
    "    predicted_all = torch.tensor([])\n",
    "    inputs_all = inputs_all.to(device)\n",
    "    labels_all = labels_all.to(device)\n",
    "    predicted_all = predicted_all.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels, inds = data\n",
    "            inputs = inputs.float()\n",
    "            labels = torch.clone(labels.long())\n",
    "            \n",
    "            # sending input to GPU/CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.squeeze(outputs, 1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            labels = labels.squeeze()\n",
    "            total += labels.numel()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            inputs_all = torch.cat((inputs_all, inputs) ,dim=0)\n",
    "            predicted_all = torch.cat((predicted_all, predicted) ,dim=0)\n",
    "            labels_all = torch.cat((labels_all, labels) ,dim=0)\n",
    "            \n",
    "    accuracy = correct/total\n",
    "    \n",
    "    print('Accuracy: {:.3}'.format(accuracy))\n",
    "    return inputs_all, labels_all, predicted_all, accuracy"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
