{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914e4f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T10:26:11.599913Z",
     "iopub.status.busy": "2022-05-03T10:26:11.599382Z",
     "iopub.status.idle": "2022-05-03T10:26:13.440987Z",
     "shell.execute_reply": "2022-05-03T10:26:13.440353Z",
     "shell.execute_reply.started": "2022-05-03T10:26:11.599859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon May  2 13:13:08 2022\n",
    "\n",
    "Data functions for handling the TUH Abnormal dataset\n",
    "\n",
    "Each method has its own description in it's header section.'\n",
    "\n",
    "The methods defined in this file are:\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "@author: Kitti\n",
    "\"\"\"\n",
    "\n",
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "from braindecode.datasets.tuh import TUHAbnormal, TUH\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, create_fixed_length_windows, scale as multiply\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a889c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T10:26:18.400608Z",
     "iopub.status.busy": "2022-05-03T10:26:18.400071Z",
     "iopub.status.idle": "2022-05-03T10:26:18.409590Z",
     "shell.execute_reply": "2022-05-03T10:26:18.408393Z",
     "shell.execute_reply.started": "2022-05-03T10:26:18.400554Z"
    },
    "lines_to_next_cell": 1,
    "tags": [],
    "title": "Function for importing the dataset"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_tuh_abnormal(path, n_jobs=1, target_name='pathological', preload=False, add_physician_reports=True):\n",
    "    \n",
    "    tuh_abnormal_raw = TUHAbnormal(\n",
    "        path=path,\n",
    "        recording_ids=None,\n",
    "        target_name=target_name,\n",
    "        preload=preload,\n",
    "        add_physician_reports=add_physician_reports,\n",
    "        n_jobs=1 if TUH.__name__ == '_TUHMock' else n_jobs,  # Mock dataset can't be loaded in parallel\n",
    "    )\n",
    "    \n",
    "    short_ch_names, ch_mapping = create_ch_mapping()\n",
    "    tuh_abnormal_selected = select_by_channels(tuh_abnormal_raw, short_ch_names, ch_mapping)\n",
    "    \n",
    "    return tuh_abnormal_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fb454-2d68-4b26-be17-6b8777a0582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_adults(tuh_abnormal):\n",
    "\n",
    "    tuh_adults_split = tuh_abnormal.split(\"age\")\n",
    "    tuh_adults_l = []\n",
    "    \n",
    "    for key, value in tuh_adults_split.items():\n",
    "        key = int(key)\n",
    "        if key >= 18:\n",
    "            tuh_adults_l.append(value)\n",
    "            \n",
    "    tuh_adults = BaseConcatDataset(tuh_adults_l)\n",
    "    \n",
    "    return tuh_adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a4db33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T08:28:06.268723Z",
     "iopub.status.busy": "2022-05-03T08:28:06.268195Z",
     "iopub.status.idle": "2022-05-03T08:28:06.287407Z",
     "shell.execute_reply": "2022-05-03T08:28:06.286652Z",
     "shell.execute_reply.started": "2022-05-03T08:28:06.268666Z"
    },
    "title": "Preprocessing functions"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_ch_mapping():\n",
    "    short_ch_names = sorted([\n",
    "        'A1', 'A2',\n",
    "        'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "        'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\n",
    "    ar_ch_names = sorted([\n",
    "        'EEG A1-REF', 'EEG A2-REF',\n",
    "        'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "        'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "        'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "        'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "    le_ch_names = sorted([\n",
    "        'EEG A1-LE', 'EEG A2-LE',\n",
    "        'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "        'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "        'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "        'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "    assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "    ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        ar_ch_names, short_ch_names)}\n",
    "    le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "        le_ch_names, short_ch_names)}\n",
    "    ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}    \n",
    "    return short_ch_names, ch_mapping\n",
    "\n",
    "\n",
    "def select_by_channels(ds, short_ch_names, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "    \n",
    "    \n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])\n",
    "    \n",
    "def create_preproc_pipeline(tmin, tmax, sfreq, clipping, ch_mapping, short_ch_names, include_tmax=True):\n",
    "    \n",
    "    preprocessors = [\n",
    "        Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=include_tmax,\n",
    "                     apply_on_array=False),\n",
    "        Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'), # mne Raw class function\n",
    "        Preprocessor(custom_rename_channels, mapping=ch_mapping, # rename channels to short channel names\n",
    "                     apply_on_array=False), #\n",
    "        Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True), # mne Raw class function\n",
    "        Preprocessor(multiply, factor=1e6, apply_on_array=True), # scaling signals to microvolt\n",
    "        Preprocessor(np.clip, a_min=-clipping, a_max=clipping, apply_on_array=True), # clip outlier values to +/- 800 micro volts\n",
    "        Preprocessor('resample', sfreq=sfreq), # mne Raw class function\n",
    "    ]\n",
    "    \n",
    "    return preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96e9721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T08:28:06.884089Z",
     "iopub.status.busy": "2022-05-03T08:28:06.883344Z",
     "iopub.status.idle": "2022-05-03T08:28:06.898115Z",
     "shell.execute_reply": "2022-05-03T08:28:06.896481Z",
     "shell.execute_reply.started": "2022-05-03T08:28:06.884029Z"
    },
    "lines_to_next_cell": 1,
    "title": "Preprocessing pipeline function"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(tuh_abnormal, tmin, tmax, sfreq, clipping, n_jobs=1):\n",
    "    \n",
    "    short_ch_names, ch_mapping = create_ch_mapping()\n",
    "    preprocessors = create_preproc_pipeline(tmin, tmax, sfreq, clipping, ch_mapping, short_ch_names, include_tmax=True)\n",
    "\n",
    "    tuh_preproc = preprocess(\n",
    "        concat_ds=tuh_abnormal,\n",
    "        preprocessors=preprocessors,\n",
    "        n_jobs=n_jobs,\n",
    "        save_dir=None\n",
    "    )\n",
    "    \n",
    "    return tuh_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084e8c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T08:28:07.391011Z",
     "iopub.status.busy": "2022-05-03T08:28:07.390509Z",
     "iopub.status.idle": "2022-05-03T08:28:07.400093Z",
     "shell.execute_reply": "2022-05-03T08:28:07.399238Z",
     "shell.execute_reply.started": "2022-05-03T08:28:07.390956Z"
    },
    "lines_to_next_cell": 2,
    "title": "Single function to call for importing and preprocessing dataset"
   },
   "outputs": [],
   "source": [
    "\n",
    "def import_and_preprocess(path, tmin, tmax, sfreq, clipping, include_tmax=True, n_jobs=1):\n",
    "    \n",
    "    tuh_abnormal_raw = import_tuh_abnormal(path, n_jobs)\n",
    "    short_ch_names, ch_mapping = create_ch_mapping()\n",
    "    tuh_abnormal_selected = select_by_channels(tuh_abnormal_raw, short_ch_names, ch_mapping)\n",
    "    preprocessors = create_preproc_pipeline(tmin, tmax, sfreq, clipping, ch_mapping, short_ch_names, include_tmax)\n",
    "    tuh_abnormal_preproc = preprocess_dataset(tuh_abnormal_selected, preprocessors, n_jobs)\n",
    "    \n",
    "    return tuh_abnormal_preproc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
