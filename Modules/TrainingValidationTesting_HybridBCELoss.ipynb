{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d1acc-eb64-4ac3-a288-b4a9305ba3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions used for the training, validation, and testing\n",
    "of the hybrid model on the TUH Abnormal dataset.\n",
    "\n",
    "Each method has its own description in it's header section.'\n",
    "\n",
    "The methods defined in this file are:\n",
    "    - train_model\n",
    "    - validate_model\n",
    "    - test_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01eaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import packages\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446aace",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "\n",
    "def train_model(model, device, criterion, optimizer, train_loader, valid_loader, n_epochs=5, early_stop_patience=2):\n",
    "    \"\"\"\n",
    "    Function for the training of the hybrid model. Also includes a call\n",
    "    on the validation of the model performance after every epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : model to be trained\n",
    "    device : device the training should take place (cpu/gpu)\n",
    "    criterion : loss function to be used during training\n",
    "    optimizer : optimizer to be used during training\n",
    "    train_loader : DataLoader training set\n",
    "    valid_loader : DataLoader validation set\n",
    "    n_epochs : number of epochs \n",
    "    early_stop_patience : patience for Early Stopping\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    model : trained model\n",
    "    train_losses_per_epoch : list containing the training losses computed after every epoch\n",
    "    train_accs_per_epoch : list containing the training accuracies computed after every epoch\n",
    "    valid_losses_per_epoch : list containing the validation losses computed after every epoch\n",
    "    valid_accs_per_epoch : list containing the validation accuracies computed after every epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(1, 1000000):\n",
    "        if len(train_loader) / i <= 20:\n",
    "            print_every = i\n",
    "            break\n",
    "    \n",
    "    model.train()\n",
    "    the_last_loss = 100\n",
    "    trigger_times = 0\n",
    "    train_losses_per_epoch, valid_losses_per_epoch = [], []\n",
    "    train_accs_per_epoch, valid_accs_per_epoch = [], []\n",
    "        \n",
    "    \n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, inds = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            \n",
    "            # sending input to GPU/CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = torch.squeeze(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.numel()\n",
    "            \n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "          \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            train_acc = correct/total\n",
    "            running_acc += train_acc\n",
    "            \n",
    "            \n",
    "            if i % print_every == print_every-1 or i+1 == len(train_loader):\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "                print('Time: {}. . [{}/{}, {}/{}] train_loss: {:.6}, train_acc: {:.3}'.format(current_time, epoch+1, n_epochs, i+1, len(train_loader), running_loss/(i+1), running_acc/(i+1)))\n",
    "\n",
    "    \n",
    "        train_losses_per_epoch.append(running_loss/len(train_loader))\n",
    "        train_accs_per_epoch.append(running_acc/len(train_loader))\n",
    "        current_loss, current_acc = validate_model(model, device, valid_loader, criterion)\n",
    "        model.train()\n",
    "        print('Current Validation Loss: {:.6}, Accuracy: {:.3}'.format(current_loss, current_acc))\n",
    "        \n",
    "            \n",
    "        if current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('Trigger Times:', trigger_times)\n",
    "    \n",
    "            if trigger_times >= early_stop_patience:\n",
    "                print('Early Stopping!\\nStart the test process.')\n",
    "                return model, train_losses_per_epoch, valid_losses_per_epoch\n",
    "                # this needs to be modified to start the testing process -> return model if turn into a function\n",
    "    \n",
    "        else:\n",
    "            print('Trigger Times: 0')\n",
    "            trigger_times = 0\n",
    "    \n",
    "        the_last_loss = current_loss\n",
    "        valid_losses_per_epoch.append(current_loss)\n",
    "        valid_accs_per_epoch.append(current_acc)\n",
    "    \n",
    "    print('Finished Training')        \n",
    "    return model, train_losses_per_epoch, train_accs_per_epoch, valid_losses_per_epoch, valid_accs_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdeafe3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_model(model, device, valid_loader, loss_function):\n",
    "    \"\"\"\n",
    "    Function for the validation of the hybrid model. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : model to be trained\n",
    "    device : device the training should take place (cpu/gpu)\n",
    "    valid_loader : DataLoader validation set\n",
    "    loss_function : loss function\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    model : trained model\n",
    "    loss_total / len(valid_loader) : loss computed over the validation set\n",
    "    accuracy : accuracy computed over the validation set\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # Test validation data\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels, inds = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            #labels = torch.clone(labels.long())\n",
    "             \n",
    "            #Sending input to GPU/CPU\n",
    "            inputs, labels = inputs.to(device),  labels.to(device)\n",
    "            \n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.squeeze(outputs, 1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss_total += loss.item()\n",
    "             \n",
    "            # Prediction for generating validation accuracy\n",
    "            predicted = torch.round(outputs)\n",
    "            total += labels.numel()\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "     \n",
    "    accuracy = correct/total\n",
    "    return loss_total / len(valid_loader), accuracy\n",
    "\n",
    "    \n",
    "\n",
    "def test_model(device, model, test_loader):\n",
    "    \"\"\"\n",
    "    Function for the testing of the hybrid model. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : model to be trained\n",
    "    device : device the training should take place (cpu/gpu)\n",
    "    test_loader : DataLoader test set\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    inputs_all : input variables in the test set\n",
    "    labels_all : targets in the test set\n",
    "    predicted_all : predictions \n",
    "    accuracy : accuracy calculated over the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    inputs_all = torch.tensor([])\n",
    "    labels_all = torch.tensor([])\n",
    "    predicted_all = torch.tensor([])\n",
    "    inputs_all = inputs_all.to(device)\n",
    "    labels_all = labels_all.to(device)\n",
    "    predicted_all = predicted_all.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels, inds = data\n",
    "            inputs = inputs.float()\n",
    "            labels = torch.clone(labels.long())\n",
    "            \n",
    "            # sending input to GPU/CPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.squeeze(outputs, 1)\n",
    "            predicted = torch.round(outputs)\n",
    "            \n",
    "            total += labels.numel()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            inputs_all = torch.cat((inputs_all, inputs) ,dim=0)\n",
    "            predicted_all = torch.cat((predicted_all, predicted) ,dim=0)\n",
    "            labels_all = torch.cat((labels_all, labels) ,dim=0)\n",
    "            \n",
    "    accuracy = correct/total\n",
    "    \n",
    "    print('Accuracy: {:.3}'.format(accuracy))\n",
    "    return inputs_all, labels_all, predicted_all, accuracy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
