{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d46f9d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T19:57:32.901431Z",
     "iopub.status.busy": "2022-05-12T19:57:32.900756Z",
     "iopub.status.idle": "2022-05-12T19:57:34.032241Z",
     "shell.execute_reply": "2022-05-12T19:57:34.031401Z",
     "shell.execute_reply.started": "2022-05-12T19:57:32.901322Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Models module include a class describing the hybrid \n",
    "deepCNN-LSTM model, along with a function creating an \n",
    "instance of the requested model. Helper\n",
    "transform functions implemented between layers.\n",
    "\n",
    "Each method has its own description in its header section.'\n",
    "\n",
    "The following class is defined in this file:\n",
    "    - DeepCNNLSTM\n",
    "\n",
    "The following methods are defined in this file:\n",
    "    - create_model\n",
    "    - reshape_lstm_input\n",
    "    - extract_output_from_lstm\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.functional import elu\n",
    "\n",
    "from braindecode.util import np_to_th\n",
    "from braindecode.models.modules import Expression, Ensure4d, AvgPool2dWithConv\n",
    "from braindecode.models.functions import (\n",
    "    safe_log, square, transpose_time_to_spat,identity, squeeze_final_output\n",
    ")\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f9ebc",
   "metadata": {
    "title": "#%% Class of the DeepCNNLSTM model"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DeepCNNLSTM(nn.Sequential):\n",
    "    \"\"\"Hybrid DeepCNN-LSTM model class.\n",
    "    CNN is based on Deep4Net model class from braindecode.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [Schirrmeister2017] Schirrmeister, R. T., Springenberg, J. T., Fiederer,\n",
    "       L. D. J., Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F.\n",
    "       & Ball, T. (2017).\n",
    "       Deep learning with convolutional neural networks for EEG decoding and\n",
    "       visualization.\n",
    "       Human Brain Mapping , Aug. 2017.\n",
    "       Online: http://dx.doi.org/10.1002/hbm.23730\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_chans,\n",
    "        n_classes,\n",
    "        input_window_samples,\n",
    "        final_conv_length,\n",
    "        n_filters_time=25,\n",
    "        n_filters_spat=25,\n",
    "        filter_time_length=10,\n",
    "        pool_time_length=3,\n",
    "        pool_time_stride=3,\n",
    "        n_filters_2=50,\n",
    "        filter_length_2=10,\n",
    "        n_filters_3=100,\n",
    "        filter_length_3=10,\n",
    "        n_filters_4=200,\n",
    "        filter_length_4=10,\n",
    "        first_nonlin=elu,\n",
    "        first_pool_mode=\"max\",\n",
    "        first_pool_nonlin=identity,\n",
    "        later_nonlin=elu,\n",
    "        later_pool_mode=\"max\",\n",
    "        later_pool_nonlin=identity,\n",
    "        drop_prob=0.5,\n",
    "        double_time_convs=False,\n",
    "        split_first_layer=True,\n",
    "        batch_norm=True,\n",
    "        batch_norm_alpha=0.1,\n",
    "        stride_before_pool=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if final_conv_length == \"auto\":\n",
    "            assert input_window_samples is not None\n",
    "        self.in_chans = in_chans\n",
    "        self.n_classes = n_classes\n",
    "        self.input_window_samples = input_window_samples\n",
    "        self.final_conv_length = final_conv_length\n",
    "        self.n_filters_time = n_filters_time\n",
    "        self.n_filters_spat = n_filters_spat\n",
    "        self.filter_time_length = filter_time_length\n",
    "        self.pool_time_length = pool_time_length\n",
    "        self.pool_time_stride = pool_time_stride\n",
    "        self.n_filters_2 = n_filters_2\n",
    "        self.filter_length_2 = filter_length_2\n",
    "        self.n_filters_3 = n_filters_3\n",
    "        self.filter_length_3 = filter_length_3\n",
    "        self.n_filters_4 = n_filters_4\n",
    "        self.filter_length_4 = filter_length_4\n",
    "        self.first_nonlin = first_nonlin\n",
    "        self.first_pool_mode = first_pool_mode\n",
    "        self.first_pool_nonlin = first_pool_nonlin\n",
    "        self.later_nonlin = later_nonlin\n",
    "        self.later_pool_mode = later_pool_mode\n",
    "        self.later_pool_nonlin = later_pool_nonlin\n",
    "        self.drop_prob = drop_prob\n",
    "        self.double_time_convs = double_time_convs\n",
    "        self.split_first_layer = split_first_layer\n",
    "        self.batch_norm = batch_norm\n",
    "        self.batch_norm_alpha = batch_norm_alpha\n",
    "        self.stride_before_pool = stride_before_pool\n",
    "\n",
    "        if self.stride_before_pool:\n",
    "            conv_stride = self.pool_time_stride\n",
    "            pool_stride = 1\n",
    "        else:\n",
    "            conv_stride = 1\n",
    "            pool_stride = self.pool_time_stride\n",
    "        self.add_module(\"ensuredims\", Ensure4d())\n",
    "        pool_class_dict = dict(max=nn.MaxPool2d, mean=AvgPool2dWithConv)\n",
    "        first_pool_class = pool_class_dict[self.first_pool_mode]\n",
    "        later_pool_class = pool_class_dict[self.later_pool_mode]\n",
    "        if self.split_first_layer:\n",
    "            self.add_module(\"dimshuffle\", Expression(transpose_time_to_spat))\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    1,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=1,\n",
    "                ),\n",
    "            )\n",
    "            self.add_module(\n",
    "                \"conv_spat\",\n",
    "                nn.Conv2d(\n",
    "                    self.n_filters_time,\n",
    "                    self.n_filters_spat,\n",
    "                    (1, self.in_chans),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_spat\n",
    "        else:\n",
    "            self.add_module(\n",
    "                \"conv_time\",\n",
    "                nn.Conv2d(\n",
    "                    self.in_chans,\n",
    "                    self.n_filters_time,\n",
    "                    (self.filter_time_length, 1),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            n_filters_conv = self.n_filters_time\n",
    "        if self.batch_norm:\n",
    "            self.add_module(\n",
    "                \"bnorm\",\n",
    "                nn.BatchNorm2d(\n",
    "                    n_filters_conv,\n",
    "                    momentum=self.batch_norm_alpha,\n",
    "                    affine=True,\n",
    "                    eps=1e-5,\n",
    "                ),\n",
    "            )\n",
    "        self.add_module(\"conv_nonlin\", Expression(self.first_nonlin))\n",
    "        self.add_module(\n",
    "            \"pool\",\n",
    "            first_pool_class(\n",
    "                kernel_size=(self.pool_time_length, 1), stride=(pool_stride, 1)\n",
    "            ),\n",
    "        )\n",
    "        self.add_module(\"pool_nonlin\", Expression(self.first_pool_nonlin))\n",
    "\n",
    "        def add_conv_pool_block(\n",
    "            model, n_filters_before, n_filters, filter_length, block_nr\n",
    "        ):\n",
    "            suffix = \"_{:d}\".format(block_nr)\n",
    "            self.add_module(\"drop\" + suffix, nn.Dropout(p=self.drop_prob))\n",
    "            self.add_module(\n",
    "                \"conv\" + suffix,\n",
    "                nn.Conv2d(\n",
    "                    n_filters_before,\n",
    "                    n_filters,\n",
    "                    (filter_length, 1),\n",
    "                    stride=(conv_stride, 1),\n",
    "                    bias=not self.batch_norm,\n",
    "                ),\n",
    "            )\n",
    "            if self.batch_norm:\n",
    "                self.add_module(\n",
    "                    \"bnorm\" + suffix,\n",
    "                    nn.BatchNorm2d(\n",
    "                        n_filters,\n",
    "                        momentum=self.batch_norm_alpha,\n",
    "                        affine=True,\n",
    "                        eps=1e-5,\n",
    "                    ),\n",
    "                )\n",
    "            self.add_module(\"nonlin\" + suffix, Expression(self.later_nonlin))\n",
    "\n",
    "            self.add_module(\n",
    "                \"pool\" + suffix,\n",
    "                later_pool_class(\n",
    "                    kernel_size=(self.pool_time_length, 1),\n",
    "                    stride=(pool_stride, 1),\n",
    "                ),\n",
    "            )\n",
    "            self.add_module(\n",
    "                \"pool_nonlin\" + suffix, Expression(self.later_pool_nonlin)\n",
    "            )\n",
    "\n",
    "        add_conv_pool_block(\n",
    "            self, n_filters_conv, self.n_filters_2, self.filter_length_2, 2\n",
    "        )\n",
    "        add_conv_pool_block(\n",
    "            self, self.n_filters_2, self.n_filters_3, self.filter_length_3, 3\n",
    "        )\n",
    "        add_conv_pool_block(\n",
    "            self, self.n_filters_3, self.n_filters_4, self.filter_length_4, 4\n",
    "        )\n",
    "\n",
    "        # self.add_module('drop_classifier', nn.Dropout(p=self.drop_prob))\n",
    "        self.eval()\n",
    "        if self.final_conv_length == \"auto\":\n",
    "            out = self(\n",
    "                np_to_th(\n",
    "                    np.ones(\n",
    "                        (1, self.in_chans, self.input_window_samples, 1),\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            n_out_time = out.cpu().data.numpy().shape[2]\n",
    "            self.final_conv_length = n_out_time\n",
    "        self.add_module(\n",
    "            \"conv_classifier\",\n",
    "            nn.Conv2d(\n",
    "                self.n_filters_4,\n",
    "                self.n_classes,\n",
    "                (self.final_conv_length, 1),\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.add_module(\"reshapeinput\", Expression(reshape_lstm_input))\n",
    "        \n",
    "        self.add_module(\n",
    "            \"LSTM\", \n",
    "            nn.LSTM(138, 69, 1,\n",
    "                batch_first=True\n",
    "            ),\n",
    "        ) \n",
    "        \n",
    "        self.add_module(\"extract_lstm\", Expression(extract_output_from_lstm))\n",
    "        \n",
    "        self.add_module(\n",
    "            \"Linear\",\n",
    "             nn.Linear(\n",
    "                 in_features= 69,\n",
    "                 out_features = 1,\n",
    "             ),\n",
    "        )\n",
    "        self.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "        \n",
    "        # Initialization, xavier is same as in our paper...\n",
    "        # was default from lasagne\n",
    "        init.xavier_uniform_(self.conv_time.weight, gain=1)\n",
    "        # maybe no bias in case of no split layer and batch norm\n",
    "        if self.split_first_layer or (not self.batch_norm):\n",
    "            init.constant_(self.conv_time.bias, 0)\n",
    "        if self.split_first_layer:\n",
    "            init.xavier_uniform_(self.conv_spat.weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                init.constant_(self.conv_spat.bias, 0)\n",
    "        if self.batch_norm:\n",
    "            init.constant_(self.bnorm.weight, 1)\n",
    "            init.constant_(self.bnorm.bias, 0)\n",
    "        param_dict = dict(list(self.named_parameters()))\n",
    "        for block_nr in range(2, 5):\n",
    "            conv_weight = param_dict[\"conv_{:d}.weight\".format(block_nr)]\n",
    "            init.xavier_uniform_(conv_weight, gain=1)\n",
    "            if not self.batch_norm:\n",
    "                conv_bias = param_dict[\"conv_{:d}.bias\".format(block_nr)]\n",
    "                init.constant_(conv_bias, 0)\n",
    "            else:\n",
    "                bnorm_weight = param_dict[\"bnorm_{:d}.weight\".format(block_nr)]\n",
    "                bnorm_bias = param_dict[\"bnorm_{:d}.bias\".format(block_nr)]\n",
    "                init.constant_(bnorm_weight, 1)\n",
    "                init.constant_(bnorm_bias, 0)\n",
    "\n",
    "        init.xavier_uniform_(self.conv_classifier.weight, gain=1)\n",
    "        init.constant_(self.conv_classifier.bias, 0)\n",
    "\n",
    "        # Start in eval mode\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0622afc",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Function for creating instances of the three models"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model(model_name, in_chans, n_classes, input_window_samples, final_conv_length):\n",
    "    \"\"\"\n",
    "    Function for creating an instance of the three different models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : name of the model to be created\n",
    "    in_chans : number of channels in the EEG data (used as input for model training)\n",
    "    n_classes : number of classes in the data\n",
    "    input_window_samples : size of window samples in ms\n",
    "    final_conv_length : final convolutional length of the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    hybrid: instance of the requested model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == \"shallow\":\n",
    "        shallowcnn = ShallowFBCSPNet(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )   \n",
    "        return shallowcnn\n",
    "        \n",
    "    elif model_name == \"deep\":\n",
    "        deepcnn = Deep4Net(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )\n",
    "        return deepcnn\n",
    "        \n",
    "    elif model_name == \"hybrid\":\n",
    "        hybrid = DeepCNNLSTM(\n",
    "            in_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length=final_conv_length,\n",
    "        )\n",
    "        return hybrid\n",
    "            \n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1125e-d709-41f1-a2ba-3dae8688083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def reshape_lstm_input(x):\n",
    "    \"\"\" Function for reshaping Conv2d output \n",
    "    to 3D, in order to match LSTM input.\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x: torch.Tensor\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    x: reshaped tensor\n",
    "    \n",
    "    \"\"\"\n",
    "    x = x.view(x.size(0), -1, x.size(3)) # [batch_size, features=channels*height, seq_len=width]\n",
    "    # [batch_size, seq_len, features] as batch_first=True\n",
    "    return x.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def extract_output_from_lstm(x):\n",
    "    \"\"\"\n",
    "    Function for extracting LSTM output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    x: output of the LSTM layer\n",
    "\n",
    "    \"\"\"\n",
    "    x = x[0]\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
