{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df656a91-fd3d-4afb-af42-14d85c5edfcb",
   "metadata": {},
   "source": [
    "This is the main script for the training and testing of the shallowCNN model,\n",
    "used for the classification of abnormal EEG activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf0fcd-899b-494d-a368-13d12456e1db",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427b867",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "from PreProcessing import import_tuh_abnormal, create_ch_mapping\n",
    "from DataTransform import data_transform, train_valid_test_split, get_parameters_for_model\n",
    "import torch\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, scale as multiply\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "from torch import optim\n",
    "from Models import create_model\n",
    "from TrainingValidationTesting_CNNs import train_model, test_model\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44942bb-08bc-4194-bd14-cb6bd1860a9d",
   "metadata": {},
   "source": [
    "## Import TUH Abnormal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f0951",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "TUH_PATH = 'TUH EEG Abnormal dataset/Abnormal/' # specify the path to the TUH Abnormal dataset\n",
    "N_JOBS = 32  # specify the number of jobs for loading and windowing\n",
    "\n",
    "# Parameters to be defined for the preprocessing pipeline\n",
    "TMIN = 1 * 60\n",
    "TMAX = 2 * 60 \n",
    "SFREQ = 100\n",
    "CLIPPING = 800\n",
    "\n",
    "tuh_abnormal = import_tuh_abnormal(TUH_PATH, N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcefe1",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create short channel names and mapping    \n",
    "short_ch_names, ch_mapping = create_ch_mapping()\n",
    "\n",
    "def select_by_channels(ds, short_ch_names, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "    \n",
    "    \n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])\n",
    "    \n",
    "short_ch_names, ch_mapping = create_ch_mapping()\n",
    "\n",
    "preprocessors = [\n",
    "        Preprocessor(custom_crop, tmin=TMIN, tmax=TMAX, include_tmax=True,\n",
    "                     apply_on_array=False),\n",
    "        Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'), # mne Raw class function\n",
    "        Preprocessor(custom_rename_channels, mapping=ch_mapping, # rename channels to short channel names\n",
    "                     apply_on_array=False), #\n",
    "        Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True), # mne Raw class function\n",
    "        Preprocessor(multiply, factor=1e6, apply_on_array=True), # scaling signals to microvolt\n",
    "        Preprocessor(np.clip, a_min=-CLIPPING, a_max=CLIPPING, apply_on_array=True), # clip outlier values to +/- 800 micro volts\n",
    "        Preprocessor('resample', sfreq=SFREQ), # mne Raw class function\n",
    "    ]\n",
    "\n",
    "tuh_preproc = preprocess(\n",
    "        concat_ds=tuh_abnormal,\n",
    "        preprocessors=preprocessors,\n",
    "        n_jobs=N_JOBS,\n",
    "        save_dir=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05169e4b-573a-4887-98df-e2add7c87a89",
   "metadata": {},
   "source": [
    "## Data Transform and Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664e08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute train-validation-test split\n",
    "\n",
    "TRAIN_SIZE=0.9 # Parameter for defining the ratio of training set (remainder defines the size of the validation set)\n",
    "\n",
    "tuh_train, tuh_val, tuh_test = train_valid_test_split(tuh_preproc, train_size=TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13b445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True, use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# Required parameters for model creation\n",
    "INPUT_WIN_SAMPLES = 6000\n",
    "INC_CHANS, INPUT_SIZE_SAMPLES = get_parameters_for_model(tuh_train)\n",
    "N_CLASSES = 2\n",
    "MODEL_NAME = \"shallow\" # it can either be shallow, deep, or hybrid\n",
    "FINAL_CONV_LENGTH = 25\n",
    "\n",
    "model = create_model(MODEL_NAME, INC_CHANS, N_CLASSES, INPUT_WIN_SAMPLES, FINAL_CONV_LENGTH)\n",
    "\n",
    "\n",
    "# If available, use multiple GPUs for training and testing\n",
    "if cuda:\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b5be5",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute DataLoader generating function\n",
    "\n",
    "BATCH_SIZE=64\n",
    "\n",
    "train_loader, val_loader, test_loader = data_transform(tuh_train, tuh_val, tuh_test, model, N_JOBS, train_size=TRAIN_SIZE, batch_size=BATCH_SIZE, input_window_samples=INPUT_WIN_SAMPLES, in_chans = INC_CHANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc089",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters required for the training of the model\n",
    "\n",
    "lr =  0.01\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "# criterion = torch.nn.BCELoss()\n",
    "n_epochs = 35  \n",
    "patience = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef75555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "trained_model, train_losses, train_accs, valid_losses, valid_accs = train_model(model, device, criterion, optimizer, train_loader, val_loader, n_epochs, patience)\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3cb69-2045-4c54-bfdd-80a437a51460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "\n",
    "PATH = './modelname.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bae9c3",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Model testing\n",
    "\n",
    "x_test, y_test, y_pred, accuracy = test_model(device, trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83dff9e-a18e-4a8e-9208-26e0a732784b",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cc0a6",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Transform tensors from test_model"
   },
   "outputs": [],
   "source": [
    "# Reshape tensors\n",
    "\n",
    "x_test = x_test.flatten().cpu()\n",
    "y_test = y_test.flatten().cpu()\n",
    "y_pred = y_pred.flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2969b",
   "metadata": {
    "title": "Training losses and accuracy plot"
   },
   "outputs": [],
   "source": [
    "# Training loss and accuracy per epoch\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(train_losses, marker=\"o\", color=\"orangered\", label=\"Training loss\")\n",
    "ax.set_xlabel(\"Number of epochs\")\n",
    "ax.set_ylabel(\"Loss\", color=\"orangered\")\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(train_accs, marker=\"o\", color=\"cornflowerblue\", label=\"Training accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\", color=\"cornflowerblue\")\n",
    "\n",
    "plt.title(\"Training loss and accuracy per epoch\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d90fe-5d5b-437d-8435-ff4cb6332f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning curve with training and validation loss\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.plot(train_losses, marker=\".\", color=\"cornflowerblue\", label='Training loss')\n",
    "plt.plot(valid_losses, marker=\".\", color=\"mediumseagreen\", label='Validation loss')\n",
    "plt.title('Training and Validation Losses', fontsize=14)\n",
    "plt.xlabel('Number of epochs', fontsize=14)\n",
    "plt.legend(frameon=False, fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d59d7b",
   "metadata": {
    "title": "ROC Curve plot"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "The ROC Curve plots two parameters: the True Positive Rate (TPR), a synonim to recall,\n",
    "and the False Positive Rate (FPR). \n",
    "The plot also shows the ROC AUC score.\n",
    "By default, the class considered as the positive (It means Abnormal in our case).\n",
    "\n",
    "'''\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred, pos_label=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f05bdf",
   "metadata": {
    "title": "Print classification report"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix and Classification Report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cl_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ec8cb",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [],
    "title": "Plot Confusion matrix"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix plot\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='YlGn')\n",
    "sns.set(font_scale=0.5)\n",
    "ax.set_title('Confusion Matrix', fontsize=16)\n",
    "ax.set_xlabel('Predicted labels', fontsize=14)\n",
    "ax.set_ylabel('True labels', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=13)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
