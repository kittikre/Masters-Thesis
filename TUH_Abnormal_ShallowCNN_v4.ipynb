{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b9dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ccc99",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!pip install torch\n",
    "!pip install mne\n",
    "!pip install braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ca00b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "# import logging\n",
    "\n",
    "from braindecode.datasets.tuh import TUHAbnormal, TUH\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows, scale as multiply)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted\n",
    "\n",
    "\n",
    "# In[2]:**Loading the data . . .**\n",
    "\n",
    "\n",
    "TUH_PATH = 'C:/Users/Kitti/Documents/Thesis/TUH/Abnormal/SSample/' # specify the path to the TUH Abnormal dataset\n",
    "N_JOBS = 2  # specify the number of jobs for loading and windowing\n",
    "tuh = TUHAbnormal(\n",
    "    path=TUH_PATH,\n",
    "    recording_ids=None,\n",
    "    target_name='pathological',\n",
    "    preload=False,\n",
    "    add_physician_reports=True,\n",
    "    n_jobs=1 if TUH.__name__ == '_TUHMock' else N_JOBS,  # Mock dataset can't\n",
    "    # be loaded in parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193ed0f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function discards all the channels found in the recordings that have\n",
    "# an incomplete configuration, and keep only those channels that we are interested in, i.e. the 21\n",
    "# channels of the international 10-20-placement). The dataset is subdivided into\n",
    "# recordings with 'le' and 'ar' reference which we will have to consider.\n",
    "\n",
    "short_ch_names = sorted([\n",
    "    'A1', 'A2',\n",
    "    'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "    'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\n",
    "ar_ch_names = sorted([\n",
    "    'EEG A1-REF', 'EEG A2-REF',\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "le_ch_names = sorted([\n",
    "    'EEG A1-LE', 'EEG A2-LE',\n",
    "    'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "    'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "    'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "    'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    ar_ch_names, short_ch_names)}\n",
    "le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    le_ch_names, short_ch_names)}\n",
    "ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}\n",
    "\n",
    "\n",
    "def select_by_channels(ds, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "tuh = select_by_channels(tuh, ch_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Based on: https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.crop\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "\n",
    "\n",
    "# Extra Custom function for renaming channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb98ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# **Preprocessor Pipeline**\n",
    "# \n",
    "# The **4th** and **5th** steps of the preprocessing, the **clipping at $\\pm800\\mu$v** and the **resampling** of the records don't have separate functions written, as we are using the mne package Raw class's functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# parameters to be defined for the preprocessing pipeline\n",
    "tmin = 1 * 60\n",
    "tmax = 21 * 60 # as the first minute of each recording is cropped, this is how we can keep 20 minutes of the recordings\n",
    "sfreq = 100\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=True,\n",
    "                 apply_on_array=False),\n",
    "    Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'), # mne Raw class function\n",
    "    Preprocessor(custom_rename_channels, mapping=ch_mapping, # rename channels to short channel names\n",
    "                 apply_on_array=False), #\n",
    "    Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True), # mne Raw class function\n",
    "    Preprocessor(multiply, factor=1e6, apply_on_array=True), # scaling signals to microvolt\n",
    "    Preprocessor(np.clip, a_min=-800, a_max=800, apply_on_array=True), # clip outlier values to +/- 800 micro volts\n",
    "    Preprocessor('resample', sfreq=sfreq), # mne Raw class function\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os.path\n",
    "# Create output folder\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, r'Output2')\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "OUT_PATH = final_directory  # please insert actual output directory here\n",
    "'''\n",
    "\n",
    "N_JOBS = 2 # the number of CPUs to be used\n",
    "\n",
    "tuh_preproc = preprocess(\n",
    "    concat_ds=tuh,\n",
    "    preprocessors=preprocessors,\n",
    "    n_jobs=N_JOBS,\n",
    "    save_dir=None\n",
    ")\n",
    "\n",
    "\n",
    "# In[13]: Train-test split\n",
    "splits = tuh_preproc.split(\"train\")\n",
    "tuh_train, tuh_eval = splits['True'], splits['False']\n",
    "\n",
    "\n",
    "# In[14]: **Building and Training a basic CNN model**\n",
    "\n",
    "\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "# to_dense_prediction_model,\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "# Set random seed to be able to roughly reproduce results\n",
    "# Note that with cudnn benchmark set to True, GPU indeterminism\n",
    "# may still make results substantially different between runs.\n",
    "# To obtain more consistent results at the cost of increased computation time,\n",
    "# you can set `cudnn_benchmark=False` in `set_random_seeds`\n",
    "# or remove `torch.backends.cudnn.benchmark = True`\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 2\n",
    "# Extract number of chans and time steps from dataset\n",
    "in_chans, input_size_samples = tuh_train[0][0].shape\n",
    "\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=1000,\n",
    "    final_conv_length=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "from braindecode.models import get_output_shape\n",
    "\n",
    "input_window_samples =1000\n",
    "n_preds_per_input = get_output_shape(model, in_chans, input_window_samples)[2] # =61\n",
    "\n",
    "train_set = create_fixed_length_windows(\n",
    "    tuh_train,\n",
    "    start_offset_samples=0,\n",
    "    stop_offset_samples=None,\n",
    "    window_size_samples=input_window_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    "    preload=False,\n",
    "    mapping={False: 0, True: 1},  # map non-digit targets\n",
    ")\n",
    "\n",
    "valid_set = create_fixed_length_windows(\n",
    "    tuh_eval,\n",
    "    start_offset_samples=0,\n",
    "    stop_offset_samples=None,\n",
    "    window_size_samples=input_window_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    "    preload=False,\n",
    "    mapping={False: 0, True: 1},  # map non-digit targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428f447",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Target transform"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set.target_transform = lambda x: np.full((61), fill_value=x)\n",
    "valid_set.target_transform = lambda x: np.full((61), fill_value=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8650383",
   "metadata": {
    "title": "Create train DataLoader"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e7462",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import optim\n",
    "from skorch.callbacks import EpochScoring\n",
    "from braindecode import EEGClassifier\n",
    "# import torch.nn.functional as F\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "# hyperparameters for training the model\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "batch_size = 64\n",
    "n_epochs = 5  # we use few epochs for speed and but more than one for plotting\n",
    "max_epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0723e",
   "metadata": {
    "title": "Alternative CNN training with iterator"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, inds = data\n",
    "        labels = torch.tensor(labels.long())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 30:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70821d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "#how to reload the saved model:\n",
    "'''\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=1000,\n",
    "    final_conv_length=1,\n",
    ")\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c72db",
   "metadata": {
    "title": "Test the model"
   },
   "outputs": [],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        inputs, labels, inds = data\n",
    "        labels = torch.tensor(labels.long())\n",
    "        \n",
    "        # calculate outputs by running samples through the network\n",
    "        outputs = model(inputs.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b7cb6",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Evaluation metrics"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(labels.flatten(), predicted.flatten())\n",
    "cl_report = classification_report(labels.flatten(), predicted.flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
